{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display:block\" direction=rtl align=right><br><br>\n",
    "    <div  style=\"width:100%;margin:100;display:block\"  display=block align=center>\n",
    "        <img width=130 align=right src=\"https://i.ibb.co/yXKQmtZ/logo1.png\" style=\"margin:0;\" />\n",
    "        <img width=170 align=left  src=\"https://i.ibb.co/wLjqFkw/logo2.png\" style=\"margin:0;\" />\n",
    "        <span><br><font size=5>University of Tehran , school of ECE</font></span>\n",
    "        <span><br><font size=3>Data Analytics Course</font></span>\n",
    "        <span><br><font size=3>Fall 2022</font></span>\n",
    "    </div><br><br><br>\n",
    "    <div style=\"display:block\" align=left display=block> \n",
    "        <font size=3>Homework 1</font><br>\n",
    "        <hr />\n",
    "        <font size=3>TA: <a href=\"mailto:mesbahamirhossein@gmail.com\">Amirhossein Mesbah</a><br></font><br>\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question1: mean and std of numbers between 10 and 1000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard Error is :  286.07691273501956\n",
      "Mean is :  505.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "arr = np.arange(10,1001,1)\n",
    "sd = arr.std()\n",
    "mean = arr.mean()\n",
    "print(\"Standard Error is : \",sd)\n",
    "print(\"Mean is : \",mean)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question2: nearest point to each random point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[65, 46, 49, 33, 70, 20, 21, 23, 57, 84,  4,  6, 45, 76, 90, 85,\n",
       "        27, 19, 74, 89, 22, 61, 29, 62, 79,  8, 55, 47, 86, 54, 56, 58,\n",
       "        41, 67, 11, 51, 82,  3, 68, 35, 75, 92, 26, 94, 31, 39, 40, 28,\n",
       "        36, 52, 59, 69, 71, 16, 12, 42, 38, 15, 99, 64, 53, 32, 93, 14,\n",
       "        66, 48, 97, 18,  2, 50,  5, 44, 34, 72, 98,  1, 13, 83, 37, 78,\n",
       "        60,  9, 96, 25, 81, 30,  7, 87, 43,  0, 63, 80, 24, 73, 17, 77,\n",
       "        10, 91, 95, 88]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rndm_points = np.random.rand(1,100)\n",
    "i = np.argsort(rndm_points)\n",
    "dist = np.diff(rndm_points[i])\n",
    "min_dist = np.r_[dist[0], np.minimum(dist[1:], dist[:-1]), dist[-1]])\n",
    "min_dist = min_dist[np.argsort(i)]\n",
    "i.shape\n",
    "i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question3: Histogram of distances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question4:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute the cell below. By running this cell, a dataset will be loaded from `patents.csv` file. In this notebook, you are asked to analyze this data in several ways. There are three numpy arrays in this dataset:\n",
    "\n",
    "- `patent_number`: a unique identifier for each patetnt\n",
    "- `patent features`: a vector of 16 features describing several properties of each patent\n",
    "- `category`: the category to which a patent belongs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('data/patents.csv')\n",
    "df.head()\n",
    "patent_number = df['publication_number'].to_numpy()\n",
    "patent_features = df['patent_embedding'].to_numpy()\n",
    "temp = []\n",
    "for i in range(patent_features.size):\n",
    "    s = str(patent_features[i])\n",
    "    s1 = s.replace(r'\\n', '')\n",
    "    temp.append(\n",
    "        np.array(s.split()[1:-1], dtype='float')[:16]\n",
    "    )\n",
    "\n",
    "patent_features = np.stack(temp)\n",
    "patent_category = df['category']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part1: Which patent has the highest norm? (Eucledian distance from origin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 2: Find the two patents that are the farthest from eachother"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 3: Write a function that, given a patent number, finds its nearest neighbour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 4: How many patents have a nearest neighbour that is in the same category?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 5: What is the average and std of distances between every pair of patents within a category? Using these calculated quantities, which cluster do you think is more condensed? Which one is more scattered?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with different Data Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## .txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: store words in a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the',\n",
       " 'zen',\n",
       " 'of',\n",
       " 'python',\n",
       " 'by',\n",
       " 'tim',\n",
       " 'peters',\n",
       " 'beautiful',\n",
       " 'is',\n",
       " 'better',\n",
       " 'than',\n",
       " 'ugly',\n",
       " 'explicit',\n",
       " 'implicit',\n",
       " 'simple',\n",
       " 'complex',\n",
       " 'complicated',\n",
       " 'flat',\n",
       " 'nested',\n",
       " 'sparse',\n",
       " 'dense',\n",
       " 'readability',\n",
       " 'counts',\n",
       " 'special',\n",
       " 'cases',\n",
       " 'arent',\n",
       " 'enough',\n",
       " 'to',\n",
       " 'break',\n",
       " 'rules',\n",
       " 'although',\n",
       " 'practicality',\n",
       " 'beats',\n",
       " 'purity',\n",
       " 'errors',\n",
       " 'should',\n",
       " 'never',\n",
       " 'pass',\n",
       " 'silently',\n",
       " 'unless',\n",
       " 'explicitly',\n",
       " 'silenced',\n",
       " 'in',\n",
       " 'face',\n",
       " 'ambiguity',\n",
       " 'refuse',\n",
       " 'temptation',\n",
       " 'guess',\n",
       " 'there',\n",
       " 'be',\n",
       " 'one',\n",
       " 'and',\n",
       " 'preferably',\n",
       " 'only',\n",
       " 'obvious',\n",
       " 'way',\n",
       " 'do',\n",
       " 'it',\n",
       " 'that',\n",
       " 'may',\n",
       " 'not',\n",
       " 'at',\n",
       " 'first',\n",
       " 'youre',\n",
       " 'dutch',\n",
       " 'now',\n",
       " 'often',\n",
       " 'right',\n",
       " 'if',\n",
       " 'implementation',\n",
       " 'hard',\n",
       " 'explain',\n",
       " 'its',\n",
       " 'a',\n",
       " 'bad',\n",
       " 'idea',\n",
       " 'easy',\n",
       " 'good',\n",
       " 'namespaces',\n",
       " 'are',\n",
       " 'honking',\n",
       " 'great',\n",
       " '',\n",
       " 'lets',\n",
       " 'more',\n",
       " 'those']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "import string\n",
    "  \n",
    "# Open the file in read mode\n",
    "text = open(\"./data/zen_of_python.txt\", \"r\")\n",
    "text = [line for line in text if line.strip() != \"\"]\n",
    "\n",
    "# Create an empty dictionary\n",
    "d = dict()\n",
    "  \n",
    "# Loop through each line of the file\n",
    "for line in text:\n",
    "    # Remove the leading spaces and newline character\n",
    "    line = line.strip()\n",
    "  \n",
    "    # Convert the characters in line to\n",
    "    # lowercase to avoid case mismatch\n",
    "    line = line.lower()\n",
    "  \n",
    "    # Remove the punctuation marks from the line\n",
    "    line = line.translate(line.maketrans(\"\", \"\", string.punctuation))\n",
    "  \n",
    "    # Split the line into words\n",
    "    words = line.split(\" \")\n",
    "  \n",
    "    # Iterate over each word in line\n",
    "    for word in words:\n",
    "        # Check if the word is already in dictionary\n",
    "        if word in d:\n",
    "            # Increment count of word by 1\n",
    "            d[word] = d[word] + 1\n",
    "        else:\n",
    "            # Add the word to dictionary with count 1\n",
    "            d[word] = 1\n",
    "\n",
    "arr = list( d.keys() )\n",
    "arr\n",
    "\n",
    "\n",
    "  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Occurrence of each character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'t': 79,\n",
       " 'h': 31,\n",
       " 'e': 92,\n",
       " ' ': 124,\n",
       " 'z': 1,\n",
       " 'n': 42,\n",
       " 'o': 43,\n",
       " 'f': 12,\n",
       " 'p': 22,\n",
       " 'y': 17,\n",
       " 'b': 21,\n",
       " 'i': 53,\n",
       " 'm': 16,\n",
       " 'r': 33,\n",
       " 's': 46,\n",
       " 'a': 53,\n",
       " 'u': 21,\n",
       " 'l': 33,\n",
       " 'g': 11,\n",
       " 'x': 6,\n",
       " 'c': 17,\n",
       " 'd': 17,\n",
       " 'k': 2,\n",
       " 'v': 5,\n",
       " 'w': 4}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_dict = dict()\n",
    "  \n",
    "# Loop through each line of the file\n",
    "for line in text:\n",
    "    # Remove the leading spaces and newline character\n",
    "    line = line.strip()\n",
    "  \n",
    "    # Convert the characters in line to\n",
    "    # lowercase to avoid case mismatch\n",
    "    line = line.lower()\n",
    "  \n",
    "    # Remove the punctuation marks from the line\n",
    "    line = line.translate(line.maketrans(\"\", \"\", string.punctuation))\n",
    "  \n",
    "\n",
    "    for i in line: \n",
    "        if i in freq_dict: \n",
    "            freq_dict[i]=freq_dict[i] + 1\n",
    "        else: \n",
    "            freq_dict[i] = 1\n",
    "\n",
    "arr = list( freq_dict)\n",
    "freq_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3: Occurrence of each word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the   6\n",
      "zen   1\n",
      "of   3\n",
      "python   1\n",
      "by   1\n",
      "tim   1\n",
      "peters   1\n",
      "beautiful   1\n",
      "is   10\n",
      "better   8\n",
      "than   8\n",
      "ugly   1\n",
      "explicit   1\n",
      "implicit   1\n",
      "simple   1\n",
      "complex   2\n",
      "complicated   1\n",
      "flat   1\n",
      "nested   1\n",
      "sparse   1\n",
      "dense   1\n",
      "readability   1\n",
      "counts   1\n",
      "special   2\n",
      "cases   1\n",
      "arent   1\n",
      "enough   1\n",
      "to   5\n",
      "break   1\n",
      "rules   1\n",
      "although   3\n",
      "practicality   1\n",
      "beats   1\n",
      "purity   1\n",
      "errors   1\n",
      "should   2\n",
      "never   3\n",
      "pass   1\n",
      "silently   1\n",
      "unless   2\n",
      "explicitly   1\n",
      "silenced   1\n",
      "in   1\n",
      "face   1\n",
      "ambiguity   1\n",
      "refuse   1\n",
      "temptation   1\n",
      "guess   1\n",
      "there   1\n",
      "be   3\n",
      "one   3\n",
      "and   1\n",
      "preferably   1\n",
      "only   1\n",
      "obvious   2\n",
      "way   2\n",
      "do   2\n",
      "it   2\n",
      "that   1\n",
      "may   2\n",
      "not   1\n",
      "at   1\n",
      "first   1\n",
      "youre   1\n",
      "dutch   1\n",
      "now   2\n",
      "often   1\n",
      "right   1\n",
      "if   2\n",
      "implementation   2\n",
      "hard   1\n",
      "explain   2\n",
      "its   1\n",
      "a   2\n",
      "bad   1\n",
      "idea   3\n",
      "easy   1\n",
      "good   1\n",
      "namespaces   1\n",
      "are   1\n",
      "honking   1\n",
      "great   1\n",
      "   1\n",
      "lets   1\n",
      "more   1\n",
      "those   1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Print the contents of dictionary\n",
    "for key in list(d.keys()):\n",
    "    print(key, \" \", d[key])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 4: Define a function for saving stats at the end of `.txt` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 5: Apply your defined function on 'zen_of_python.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: number of features and data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Rows : 15689\n",
      "Number of Columns :  5\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"./data/patents.csv\")\n",
    "df.shape\n",
    "\n",
    "print(\"Number of Rows :\",df.shape[0])\n",
    "print(\"Number of Columns : \",df.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Name of Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name Of the features are : \n",
      "['publication_number', 'title', 'cpc_code', 'patent_embedding', 'category']\n"
     ]
    }
   ],
   "source": [
    "print(\"Name of the features are : \")\n",
    "print(list(df.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3: Print Stats of Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    15689.000000\n",
       "mean         3.854229\n",
       "std          2.499307\n",
       "min          0.000000\n",
       "25%          1.000000\n",
       "50%          4.000000\n",
       "75%          6.000000\n",
       "max          7.000000\n",
       "Name: category, dtype: float64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['category'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 4: print rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>publication_number</th>\n",
       "      <th>title</th>\n",
       "      <th>cpc_code</th>\n",
       "      <th>patent_embedding</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>US-2019250858-A1</td>\n",
       "      <td>memory controller and operating method thereof</td>\n",
       "      <td>G06F3/061</td>\n",
       "      <td>[ 0.00135472  0.01564001 -0.04858465  0.039866...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>US-1000462-A</td>\n",
       "      <td>corn planter</td>\n",
       "      <td>A01C9/00</td>\n",
       "      <td>[-4.44490612e-02  2.48770583e-02 -5.62837869e-...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KR-200146416-Y1</td>\n",
       "      <td>antitheft vehicle security system</td>\n",
       "      <td>B60R25/209</td>\n",
       "      <td>[-2.53110677e-02 -2.04547048e-02  8.63679312e-...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KR-0160422-B1</td>\n",
       "      <td>a door opening and shutting apparatus and meth...</td>\n",
       "      <td>D06F37/42</td>\n",
       "      <td>[ 1.21761542e-02  1.97522007e-02 -6.62921891e-...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>US-952306-A</td>\n",
       "      <td>spray burner</td>\n",
       "      <td>B05B1/3033</td>\n",
       "      <td>[-0.00214472  0.01606156 -0.09518531  0.060160...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  publication_number                                              title  \\\n",
       "0   US-2019250858-A1     memory controller and operating method thereof   \n",
       "1       US-1000462-A                                       corn planter   \n",
       "2    KR-200146416-Y1                  antitheft vehicle security system   \n",
       "3      KR-0160422-B1  a door opening and shutting apparatus and meth...   \n",
       "4        US-952306-A                                       spray burner   \n",
       "\n",
       "     cpc_code                                   patent_embedding  category  \n",
       "0   G06F3/061  [ 0.00135472  0.01564001 -0.04858465  0.039866...         1  \n",
       "1    A01C9/00  [-4.44490612e-02  2.48770583e-02 -5.62837869e-...         6  \n",
       "2  B60R25/209  [-2.53110677e-02 -2.04547048e-02  8.63679312e-...         0  \n",
       "3   D06F37/42  [ 1.21761542e-02  1.97522007e-02 -6.62921891e-...         1  \n",
       "4  B05B1/3033  [-0.00214472  0.01606156 -0.09518531  0.060160...         0  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5 first rows\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>publication_number</th>\n",
       "      <th>title</th>\n",
       "      <th>cpc_code</th>\n",
       "      <th>patent_embedding</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15684</th>\n",
       "      <td>AT-415717-T</td>\n",
       "      <td>method and device for produce a low pressure w...</td>\n",
       "      <td>H01M8/04104</td>\n",
       "      <td>[ 1.77878514e-02  3.53233777e-02 -3.37363742e-...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15685</th>\n",
       "      <td>AT-424202-T</td>\n",
       "      <td>substitute _NUMBER_ thio _NUMBER_ _NUMBER_ dic...</td>\n",
       "      <td>C07D417/12</td>\n",
       "      <td>[-0.03664465 -0.01075565 -0.02483719 -0.033502...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15686</th>\n",
       "      <td>CA-2952951-A1</td>\n",
       "      <td>end tip for a vehicle wiper blade</td>\n",
       "      <td>B60S1/3894</td>\n",
       "      <td>[-4.39246558e-02  2.96350904e-02 -2.31920835e-...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15687</th>\n",
       "      <td>CH-608317-A</td>\n",
       "      <td>process for the compressive shrinkage of a web...</td>\n",
       "      <td>D06C21/00</td>\n",
       "      <td>[-3.34328553e-03  1.02757774e-02 -2.01825500e-...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15688</th>\n",
       "      <td>CN-100513251-C</td>\n",
       "      <td>system and process for open cover vessel hull</td>\n",
       "      <td>B63B71/00</td>\n",
       "      <td>[-1.98921170e-02  3.07969116e-02 -2.46879123e-...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      publication_number                                              title  \\\n",
       "15684        AT-415717-T  method and device for produce a low pressure w...   \n",
       "15685        AT-424202-T  substitute _NUMBER_ thio _NUMBER_ _NUMBER_ dic...   \n",
       "15686      CA-2952951-A1                  end tip for a vehicle wiper blade   \n",
       "15687        CH-608317-A  process for the compressive shrinkage of a web...   \n",
       "15688     CN-100513251-C      system and process for open cover vessel hull   \n",
       "\n",
       "          cpc_code                                   patent_embedding  \\\n",
       "15684  H01M8/04104  [ 1.77878514e-02  3.53233777e-02 -3.37363742e-...   \n",
       "15685   C07D417/12  [-0.03664465 -0.01075565 -0.02483719 -0.033502...   \n",
       "15686   B60S1/3894  [-4.39246558e-02  2.96350904e-02 -2.31920835e-...   \n",
       "15687    D06C21/00  [-3.34328553e-03  1.02757774e-02 -2.01825500e-...   \n",
       "15688    B63B71/00  [-1.98921170e-02  3.07969116e-02 -2.46879123e-...   \n",
       "\n",
       "       category  \n",
       "15684         1  \n",
       "15685         5  \n",
       "15686         0  \n",
       "15687         6  \n",
       "15688         6  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5 last rows\n",
    "df.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>publication_number</th>\n",
       "      <th>title</th>\n",
       "      <th>cpc_code</th>\n",
       "      <th>patent_embedding</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15034</th>\n",
       "      <td>WO-2018046247-A1</td>\n",
       "      <td>electric system for a vehicle</td>\n",
       "      <td>B60T8/1708</td>\n",
       "      <td>[ 0.00877162  0.05072464 -0.00613593  0.062725...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11758</th>\n",
       "      <td>CN-1529833-A</td>\n",
       "      <td>photosensitive color composition colour filter...</td>\n",
       "      <td>G03F7/0007</td>\n",
       "      <td>[-1.75427776e-02  1.84562579e-02 -5.31301610e-...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11247</th>\n",
       "      <td>CN-109202988-A</td>\n",
       "      <td>a kind of prepared slice of chinese crude drug...</td>\n",
       "      <td>B26D1/08</td>\n",
       "      <td>[ 0.0105079   0.01217971 -0.02279116  0.045483...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13370</th>\n",
       "      <td>US-7090581-B2</td>\n",
       "      <td>point management system and server</td>\n",
       "      <td>G07F17/3255</td>\n",
       "      <td>[-0.03280511  0.01779306 -0.01703667  0.038362...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1181</th>\n",
       "      <td>KR-200439602-Y1</td>\n",
       "      <td>digital door lock</td>\n",
       "      <td>E05B9/08</td>\n",
       "      <td>[-0.02072063  0.034958    0.01051822  0.082042...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      publication_number                                              title  \\\n",
       "15034   WO-2018046247-A1                      electric system for a vehicle   \n",
       "11758       CN-1529833-A  photosensitive color composition colour filter...   \n",
       "11247     CN-109202988-A  a kind of prepared slice of chinese crude drug...   \n",
       "13370      US-7090581-B2                 point management system and server   \n",
       "1181     KR-200439602-Y1                                  digital door lock   \n",
       "\n",
       "          cpc_code                                   patent_embedding  \\\n",
       "15034   B60T8/1708  [ 0.00877162  0.05072464 -0.00613593  0.062725...   \n",
       "11758   G03F7/0007  [-1.75427776e-02  1.84562579e-02 -5.31301610e-...   \n",
       "11247     B26D1/08  [ 0.0105079   0.01217971 -0.02279116  0.045483...   \n",
       "13370  G07F17/3255  [-0.03280511  0.01779306 -0.01703667  0.038362...   \n",
       "1181      E05B9/08  [-0.02072063  0.034958    0.01051822  0.082042...   \n",
       "\n",
       "       category  \n",
       "15034         3  \n",
       "11758         6  \n",
       "11247         1  \n",
       "13370         6  \n",
       "1181          7  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5 random row\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 5: use iloc and loc to select rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1024    device for purple coupling of rotatable axle o...\n",
       "1025                                     heat pump system\n",
       "1026    condensation dryer comprise a heat pump and me...\n",
       "1027                     animal _NUMBER_ plead ingredient\n",
       "1028                      electrostatic dust precipitator\n",
       "                              ...                        \n",
       "2044                  crystalline anti htnfalpha antibody\n",
       "2045    method information processing apparatus and co...\n",
       "2046        pork rind bait and method of prepare the same\n",
       "2047    process for the treatment of titanium contain ...\n",
       "2048    air condition system of a motor vehicle and me...\n",
       "Name: title, Length: 1025, dtype: object"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loc\n",
    "df.loc[1024:2048,'title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1024    device for purple coupling of rotatable axle o...\n",
       "1025                                     heat pump system\n",
       "1026    condensation dryer comprise a heat pump and me...\n",
       "1027                     animal _NUMBER_ plead ingredient\n",
       "1028                      electrostatic dust precipitator\n",
       "                              ...                        \n",
       "2044                  crystalline anti htnfalpha antibody\n",
       "2045    method information processing apparatus and co...\n",
       "2046        pork rind bait and method of prepare the same\n",
       "2047    process for the treatment of titanium contain ...\n",
       "2048    air condition system of a motor vehicle and me...\n",
       "Name: title, Length: 1025, dtype: object"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# iloc\n",
    "df.loc[1024:2048,'title']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 5: Check Dataframe for NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "publication_number    False\n",
       "title                 False\n",
       "cpc_code              False\n",
       "patent_embedding      False\n",
       "category              False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 6: Check Dataframe for duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate Rows :\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>publication_number</th>\n",
       "      <th>title</th>\n",
       "      <th>cpc_code</th>\n",
       "      <th>patent_embedding</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1739</th>\n",
       "      <td>AU-2011202417-A1</td>\n",
       "      <td>a wall form in soil the wall include a hollow ...</td>\n",
       "      <td>E02D5/18</td>\n",
       "      <td>[ 3.92072555e-03  3.35453786e-02 -2.88293511e-...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5696</th>\n",
       "      <td>EP-3096560-A4</td>\n",
       "      <td>method and user equipment for block network ac...</td>\n",
       "      <td>H04W48/06</td>\n",
       "      <td>[-3.0044878e-02 -4.4037402e-05 -2.3655588e-02 ...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6496</th>\n",
       "      <td>US-2018076003-A1</td>\n",
       "      <td>method and apparatus for a porous electrospray...</td>\n",
       "      <td>H01J37/08</td>\n",
       "      <td>[ 0.02056626  0.04025198 -0.04704187  0.061253...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6962</th>\n",
       "      <td>US-2018328001-A1</td>\n",
       "      <td>boom assembly for a trencher</td>\n",
       "      <td>E02F5/14</td>\n",
       "      <td>[ 1.52878952e-03  3.42151672e-02 -4.17193323e-...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9408</th>\n",
       "      <td>JP-5702147-B2</td>\n",
       "      <td>electroactive material</td>\n",
       "      <td>H01L51/0035</td>\n",
       "      <td>[ 0.01078738 -0.01581865 -0.01463019  0.023458...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9980</th>\n",
       "      <td>JP-6373410-B2</td>\n",
       "      <td>end of life determination and prediction for i...</td>\n",
       "      <td>A61N1/36128</td>\n",
       "      <td>[-3.00560612e-03  5.31513337e-03 -1.25307012e-...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11142</th>\n",
       "      <td>AU-2012324531-A1</td>\n",
       "      <td>biomarkers useful for detection of type grade ...</td>\n",
       "      <td>C12Q1/6886</td>\n",
       "      <td>[ 0.01898381  0.01144431 -0.04808485  0.079074...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13850</th>\n",
       "      <td>US-2018042871-A1</td>\n",
       "      <td>bicyclic analgesic compound</td>\n",
       "      <td>A61K31/16</td>\n",
       "      <td>[ 4.39326465e-02 -1.77983195e-02 -8.26886818e-...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14823</th>\n",
       "      <td>HK-1225899-A1</td>\n",
       "      <td>apparatus system and method of secure communic...</td>\n",
       "      <td>H04W12/04</td>\n",
       "      <td>[-0.00121724 -0.00263928  0.0009811   0.056798...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      publication_number                                              title  \\\n",
       "1739    AU-2011202417-A1  a wall form in soil the wall include a hollow ...   \n",
       "5696       EP-3096560-A4  method and user equipment for block network ac...   \n",
       "6496    US-2018076003-A1  method and apparatus for a porous electrospray...   \n",
       "6962    US-2018328001-A1                       boom assembly for a trencher   \n",
       "9408       JP-5702147-B2                             electroactive material   \n",
       "9980       JP-6373410-B2  end of life determination and prediction for i...   \n",
       "11142   AU-2012324531-A1  biomarkers useful for detection of type grade ...   \n",
       "13850   US-2018042871-A1                        bicyclic analgesic compound   \n",
       "14823      HK-1225899-A1  apparatus system and method of secure communic...   \n",
       "\n",
       "          cpc_code                                   patent_embedding  \\\n",
       "1739      E02D5/18  [ 3.92072555e-03  3.35453786e-02 -2.88293511e-...   \n",
       "5696     H04W48/06  [-3.0044878e-02 -4.4037402e-05 -2.3655588e-02 ...   \n",
       "6496     H01J37/08  [ 0.02056626  0.04025198 -0.04704187  0.061253...   \n",
       "6962      E02F5/14  [ 1.52878952e-03  3.42151672e-02 -4.17193323e-...   \n",
       "9408   H01L51/0035  [ 0.01078738 -0.01581865 -0.01463019  0.023458...   \n",
       "9980   A61N1/36128  [-3.00560612e-03  5.31513337e-03 -1.25307012e-...   \n",
       "11142   C12Q1/6886  [ 0.01898381  0.01144431 -0.04808485  0.079074...   \n",
       "13850    A61K31/16  [ 4.39326465e-02 -1.77983195e-02 -8.26886818e-...   \n",
       "14823    H04W12/04  [-0.00121724 -0.00263928  0.0009811   0.056798...   \n",
       "\n",
       "       category  \n",
       "1739          1  \n",
       "5696          6  \n",
       "6496          1  \n",
       "6962          1  \n",
       "9408          2  \n",
       "9980          6  \n",
       "11142         1  \n",
       "13850         2  \n",
       "14823         6  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicate = df[df.duplicated()]\n",
    " \n",
    "print(\"Duplicate Rows :\")\n",
    " \n",
    "# Print the resultant Dataframe\n",
    "duplicate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 7: Use `Lambda` Function for calculating word counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>publication_number</th>\n",
       "      <th>title</th>\n",
       "      <th>cpc_code</th>\n",
       "      <th>patent_embedding</th>\n",
       "      <th>category</th>\n",
       "      <th>title_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>US-2019250858-A1</td>\n",
       "      <td>memory controller and operating method thereof</td>\n",
       "      <td>G06F3/061</td>\n",
       "      <td>[ 0.00135472  0.01564001 -0.04858465  0.039866...</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>US-1000462-A</td>\n",
       "      <td>corn planter</td>\n",
       "      <td>A01C9/00</td>\n",
       "      <td>[-4.44490612e-02  2.48770583e-02 -5.62837869e-...</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KR-200146416-Y1</td>\n",
       "      <td>antitheft vehicle security system</td>\n",
       "      <td>B60R25/209</td>\n",
       "      <td>[-2.53110677e-02 -2.04547048e-02  8.63679312e-...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KR-0160422-B1</td>\n",
       "      <td>a door opening and shutting apparatus and meth...</td>\n",
       "      <td>D06F37/42</td>\n",
       "      <td>[ 1.21761542e-02  1.97522007e-02 -6.62921891e-...</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>US-952306-A</td>\n",
       "      <td>spray burner</td>\n",
       "      <td>B05B1/3033</td>\n",
       "      <td>[-0.00214472  0.01606156 -0.09518531  0.060160...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15684</th>\n",
       "      <td>AT-415717-T</td>\n",
       "      <td>method and device for produce a low pressure w...</td>\n",
       "      <td>H01M8/04104</td>\n",
       "      <td>[ 1.77878514e-02  3.53233777e-02 -3.37363742e-...</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15685</th>\n",
       "      <td>AT-424202-T</td>\n",
       "      <td>substitute _NUMBER_ thio _NUMBER_ _NUMBER_ dic...</td>\n",
       "      <td>C07D417/12</td>\n",
       "      <td>[-0.03664465 -0.01075565 -0.02483719 -0.033502...</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15686</th>\n",
       "      <td>CA-2952951-A1</td>\n",
       "      <td>end tip for a vehicle wiper blade</td>\n",
       "      <td>B60S1/3894</td>\n",
       "      <td>[-4.39246558e-02  2.96350904e-02 -2.31920835e-...</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15687</th>\n",
       "      <td>CH-608317-A</td>\n",
       "      <td>process for the compressive shrinkage of a web...</td>\n",
       "      <td>D06C21/00</td>\n",
       "      <td>[-3.34328553e-03  1.02757774e-02 -2.01825500e-...</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15688</th>\n",
       "      <td>CN-100513251-C</td>\n",
       "      <td>system and process for open cover vessel hull</td>\n",
       "      <td>B63B71/00</td>\n",
       "      <td>[-1.98921170e-02  3.07969116e-02 -2.46879123e-...</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15689 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      publication_number                                              title  \\\n",
       "0       US-2019250858-A1     memory controller and operating method thereof   \n",
       "1           US-1000462-A                                       corn planter   \n",
       "2        KR-200146416-Y1                  antitheft vehicle security system   \n",
       "3          KR-0160422-B1  a door opening and shutting apparatus and meth...   \n",
       "4            US-952306-A                                       spray burner   \n",
       "...                  ...                                                ...   \n",
       "15684        AT-415717-T  method and device for produce a low pressure w...   \n",
       "15685        AT-424202-T  substitute _NUMBER_ thio _NUMBER_ _NUMBER_ dic...   \n",
       "15686      CA-2952951-A1                  end tip for a vehicle wiper blade   \n",
       "15687        CH-608317-A  process for the compressive shrinkage of a web...   \n",
       "15688     CN-100513251-C      system and process for open cover vessel hull   \n",
       "\n",
       "          cpc_code                                   patent_embedding  \\\n",
       "0        G06F3/061  [ 0.00135472  0.01564001 -0.04858465  0.039866...   \n",
       "1         A01C9/00  [-4.44490612e-02  2.48770583e-02 -5.62837869e-...   \n",
       "2       B60R25/209  [-2.53110677e-02 -2.04547048e-02  8.63679312e-...   \n",
       "3        D06F37/42  [ 1.21761542e-02  1.97522007e-02 -6.62921891e-...   \n",
       "4       B05B1/3033  [-0.00214472  0.01606156 -0.09518531  0.060160...   \n",
       "...            ...                                                ...   \n",
       "15684  H01M8/04104  [ 1.77878514e-02  3.53233777e-02 -3.37363742e-...   \n",
       "15685   C07D417/12  [-0.03664465 -0.01075565 -0.02483719 -0.033502...   \n",
       "15686   B60S1/3894  [-4.39246558e-02  2.96350904e-02 -2.31920835e-...   \n",
       "15687    D06C21/00  [-3.34328553e-03  1.02757774e-02 -2.01825500e-...   \n",
       "15688    B63B71/00  [-1.98921170e-02  3.07969116e-02 -2.46879123e-...   \n",
       "\n",
       "       category  title_length  \n",
       "0             1             6  \n",
       "1             6             2  \n",
       "2             0             4  \n",
       "3             1            12  \n",
       "4             0             2  \n",
       "...         ...           ...  \n",
       "15684         1            17  \n",
       "15685         5            13  \n",
       "15686         0             7  \n",
       "15687         6            12  \n",
       "15688         6             8  \n",
       "\n",
       "[15689 rows x 6 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['title_length'] = df.title.apply(lambda x: len(x.split()))\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 8: Plot Histogram of Word counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.title_length.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Number of Total Commits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = './data/git_log.log'\n",
    "# reading\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>commit</th>\n",
       "      <th>Auther</th>\n",
       "      <th>Email</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4d3d9de655faa813781027d8b1baed819c6a56fe</td>\n",
       "      <td>Markus Harrer</td>\n",
       "      <td>feststelltaste@googlemail.com</td>\n",
       "      <td>Tue Mar 5 22:32:20 2019 +0100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b836a492b2d5916397be9880f548121a9b398db1</td>\n",
       "      <td>Markus Harrer</td>\n",
       "      <td>feststelltaste@googlemail.com</td>\n",
       "      <td>Tue Mar 5 13:38:07 2019 +0100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3a16dd99f4e7758a38b17e911eb78ba1dc7d871f</td>\n",
       "      <td>Markus Harrer</td>\n",
       "      <td>feststelltaste@googlemail.com</td>\n",
       "      <td>Tue Mar 5 13:35:38 2019 +0100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7575b4731833a782f3de5d4686e9a0e3e2349ca6</td>\n",
       "      <td>Markus Harrer</td>\n",
       "      <td>feststelltaste@googlemail.com</td>\n",
       "      <td>Tue Mar 5 13:34:35 2019 +0100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>208f665e17f3d8650b82f1169bbb5fab7e67807b</td>\n",
       "      <td>Markus Harrer</td>\n",
       "      <td>feststelltaste@googlemail.com</td>\n",
       "      <td>Thu Nov 15 18:39:27 2018 +0100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531</th>\n",
       "      <td>d5cf15107a3dc797354e5d3c353a846f377a64a1</td>\n",
       "      <td>Keith Donald</td>\n",
       "      <td>kdonald@vmware.com</td>\n",
       "      <td>Tue May 5 22:12:23 2009 +0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532</th>\n",
       "      <td>556824d7c7f31405deb6ba7bc066cf957eed0be5</td>\n",
       "      <td>Keith Donald</td>\n",
       "      <td>kdonald@vmware.com</td>\n",
       "      <td>Tue May 5 22:00:59 2009 +0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533</th>\n",
       "      <td>7ff5e857fdb41a9f3e012c56390c2baa1f8b0f3e</td>\n",
       "      <td>Keith Donald</td>\n",
       "      <td>kdonald@vmware.com</td>\n",
       "      <td>Tue May 5 17:30:38 2009 +0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534</th>\n",
       "      <td>f09d67cc1c216b445d01f1893f37ff391bb3b4b7</td>\n",
       "      <td>Keith Donald</td>\n",
       "      <td>kdonald@vmware.com</td>\n",
       "      <td>Tue May 5 17:22:49 2009 +0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535</th>\n",
       "      <td>349fdef18bcf688709f19097c140c69724905768</td>\n",
       "      <td>michaelisvy</td>\n",
       "      <td>misvy@vmware.com</td>\n",
       "      <td>Wed Jan 9 01:05:18 2013 -0800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>536 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       commit         Auther  \\\n",
       "0    4d3d9de655faa813781027d8b1baed819c6a56fe  Markus Harrer   \n",
       "1    b836a492b2d5916397be9880f548121a9b398db1  Markus Harrer   \n",
       "2    3a16dd99f4e7758a38b17e911eb78ba1dc7d871f  Markus Harrer   \n",
       "3    7575b4731833a782f3de5d4686e9a0e3e2349ca6  Markus Harrer   \n",
       "4    208f665e17f3d8650b82f1169bbb5fab7e67807b  Markus Harrer   \n",
       "..                                        ...            ...   \n",
       "531  d5cf15107a3dc797354e5d3c353a846f377a64a1   Keith Donald   \n",
       "532  556824d7c7f31405deb6ba7bc066cf957eed0be5   Keith Donald   \n",
       "533  7ff5e857fdb41a9f3e012c56390c2baa1f8b0f3e   Keith Donald   \n",
       "534  f09d67cc1c216b445d01f1893f37ff391bb3b4b7   Keith Donald   \n",
       "535  349fdef18bcf688709f19097c140c69724905768    michaelisvy   \n",
       "\n",
       "                             Email                              Date  \n",
       "0    feststelltaste@googlemail.com     Tue Mar 5 22:32:20 2019 +0100  \n",
       "1    feststelltaste@googlemail.com     Tue Mar 5 13:38:07 2019 +0100  \n",
       "2    feststelltaste@googlemail.com     Tue Mar 5 13:35:38 2019 +0100  \n",
       "3    feststelltaste@googlemail.com     Tue Mar 5 13:34:35 2019 +0100  \n",
       "4    feststelltaste@googlemail.com    Thu Nov 15 18:39:27 2018 +0100  \n",
       "..                             ...                               ...  \n",
       "531             kdonald@vmware.com     Tue May 5 22:12:23 2009 +0000  \n",
       "532             kdonald@vmware.com     Tue May 5 22:00:59 2009 +0000  \n",
       "533             kdonald@vmware.com     Tue May 5 17:30:38 2009 +0000  \n",
       "534             kdonald@vmware.com     Tue May 5 17:22:49 2009 +0000  \n",
       "535               misvy@vmware.com     Wed Jan 9 01:05:18 2013 -0800  \n",
       "\n",
       "[536 rows x 4 columns]"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def log_to_dataframe(location):\n",
    "    with open(location, mode='r', encoding='UTF-8') as f:\n",
    "        commit_list = []\n",
    "        Author_list = []\n",
    "        email_list = []\n",
    "        Date_list = []\n",
    "        for line in f:\n",
    "            if line.startswith('commit'):\n",
    "                commit = line.split(\" \")[1].rstrip()\n",
    "                commit_list.append(commit)\n",
    "            elif \"Author:\" in line:\n",
    "                Author = line.split(\": \")[1].rstrip()\n",
    "                email = Author.split(\" <\")[1][:-1]\n",
    "                Author = Author.split(\" <\")[0]\n",
    "                Author_list.append(Author)\n",
    "                email_list.append(email)\n",
    "            elif \"Date:\" in line:\n",
    "                date = line.split(\": \")[1].rstrip()\n",
    "                Date_list.append(date)\n",
    "            else:\n",
    "                pass\n",
    "    main_df = pd.DataFrame({\"commit\": commit_list, \"Auther\": Author_list, \"Email\": email_list, \"Date\": Date_list})\n",
    "    return main_df\n",
    "\n",
    "\n",
    "log_df = log_to_dataframe('./data/git_log.log')\n",
    "log_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Extract Developer name, Email, Commit Count and last commit date and create a Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3: Developers with Maximum and Minimum Commit count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Create Dataframe from Json files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ø¯Ø± Ø§ÛŒÙ† Ù‚Ø³Ù…Øª Ø§Ø¨ØªØ¯Ø§ ØªÙ…Ø§Ù… ÙØ§ÛŒÙ„ Ù‡Ø§ÛŒ Ù…ÙˆØ¬ÙˆØ¯ Ø¯Ø± Ù¾ÙˆØ´Ù‡ Ù‡Ø§ÛŒ Ø¯Ø§Ø¯Ù‡ Ø´Ø¯Ù‡ Ø±Ø§ Ø¯Ø± ÛŒÚ© Ø¢Ø±Ø§ÛŒÙ‡ Ø°Ø®ÛŒØ±Ù‡ Ù…ÛŒ Ú©Ù†ÛŒÙ…. Ø³Ù¾Ø³ Ø¨Ø§ Ù¾Ø§Ø±Ø³ Ú©Ø±Ø¯Ù† Ù‡Ø± Ú©Ø¯Ø§Ù… Ø§Ø² ÙØ§ÛŒÙ„ Ù‡Ø§ÛŒ Ø¬ÛŒØ³ÙˆÙ†ØŒ ÛŒÚ© Ø¯ÛŒØªØ§ÙØ±ÛŒÙ… Ù…ÛŒ Ø³Ø§Ø²ÛŒÙ….\n",
    "Ø¯Ø± Ø§Ø¯Ø§Ù…Ù‡ Ø³ØªÙˆÙ† Ø²Ù…Ø§ Ø±Ø§ Ø§Ø² Ø­Ø§Ù„Øª Ù…ØªÙ† Ø¨Ù‡ ÙØ±Ù…Øª Ø²Ù…Ø§Ù†ÛŒ Ø¯Ø± Ø¢ÙˆØ±Ø¯ÛŒÙ….\n",
    "Ùˆ Ø¯Ø± Ø§Ù†ØªÙ‡Ø§ÛŒ Ø§ÛŒÙ† Ø¨Ø®Ø´ Ø§Ø² Ú©Ù„ Ø¯Ø§Ø¯Ù‡ Ù‡Ø§ Ø³ØªÙˆÙ† Ù‡Ø§ÛŒ Ø¯Ø§Ø¯Ù‡ Ø´Ø¯Ù‡ Ø±Ø§ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ú©Ø±Ø¯ÛŒÙ…."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Lang</th>\n",
       "      <th>Record_date</th>\n",
       "      <th>url</th>\n",
       "      <th>Description</th>\n",
       "      <th>Category</th>\n",
       "      <th>Tags</th>\n",
       "      <th>Speakers</th>\n",
       "      <th>Duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Load Testing a Django Application using LocustIO</td>\n",
       "      <td>eng</td>\n",
       "      <td>2021-06-04</td>\n",
       "      <td>https://www.youtube.com/watch?v=2rvsOQrbLuc</td>\n",
       "      <td>Fed up of using existing tools for determining...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[Django, DjangoConEU, djangoconeu2021]</td>\n",
       "      <td>[Pranjal Jain, Vibhash Chandra]</td>\n",
       "      <td>1993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Python-based data science to understand knowle...</td>\n",
       "      <td>eng</td>\n",
       "      <td>2016-03-10</td>\n",
       "      <td>http://youtu.be/pVd2v7fgxwU</td>\n",
       "      <td>All kinds of businesses are using data science...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[Daniel E. Acuna]</td>\n",
       "      <td>2700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Reverse-engineering Ian Bicking's brain: insid...</td>\n",
       "      <td>eng</td>\n",
       "      <td>2011-02-10</td>\n",
       "      <td>https://archive.org/details/pyvideo_568___reve...</td>\n",
       "      <td>-  1 http://us.pycon.org/2011/schedule/session...</td>\n",
       "      <td>ChiPy</td>\n",
       "      <td>[chipy, ianbicking, pip, virtualenv]</td>\n",
       "      <td>[Carl Meyer]</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Build, deploy and scale Django, GraphQL and SPA</td>\n",
       "      <td>eng</td>\n",
       "      <td>2021-06-04</td>\n",
       "      <td>https://www.youtube.com/watch?v=x9I6WaaLC3U</td>\n",
       "      <td>After building, deploying and scaling a dozen ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[Django, DjangoConEU, djangoconeu2021]</td>\n",
       "      <td>[dhilipsiva]</td>\n",
       "      <td>1837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hash Functions and You: Partners in Freedom</td>\n",
       "      <td>eng</td>\n",
       "      <td>2015-04-12</td>\n",
       "      <td>https://www.youtube.com/watch?v=IGwNQfjLTp0</td>\n",
       "      <td>Our trusty friend, the hash function, is as cr...</td>\n",
       "      <td>PyCon US 2015</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Curtis Lassam]</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title Lang Record_date  \\\n",
       "0   Load Testing a Django Application using LocustIO  eng  2021-06-04   \n",
       "1  Python-based data science to understand knowle...  eng  2016-03-10   \n",
       "2  Reverse-engineering Ian Bicking's brain: insid...  eng  2011-02-10   \n",
       "3    Build, deploy and scale Django, GraphQL and SPA  eng  2021-06-04   \n",
       "4        Hash Functions and You: Partners in Freedom  eng  2015-04-12   \n",
       "\n",
       "                                                 url  \\\n",
       "0        https://www.youtube.com/watch?v=2rvsOQrbLuc   \n",
       "1                        http://youtu.be/pVd2v7fgxwU   \n",
       "2  https://archive.org/details/pyvideo_568___reve...   \n",
       "3        https://www.youtube.com/watch?v=x9I6WaaLC3U   \n",
       "4        https://www.youtube.com/watch?v=IGwNQfjLTp0   \n",
       "\n",
       "                                         Description       Category  \\\n",
       "0  Fed up of using existing tools for determining...            NaN   \n",
       "1  All kinds of businesses are using data science...            NaN   \n",
       "2  -  1 http://us.pycon.org/2011/schedule/session...          ChiPy   \n",
       "3  After building, deploying and scaling a dozen ...            NaN   \n",
       "4  Our trusty friend, the hash function, is as cr...  PyCon US 2015   \n",
       "\n",
       "                                     Tags                         Speakers  \\\n",
       "0  [Django, DjangoConEU, djangoconeu2021]  [Pranjal Jain, Vibhash Chandra]   \n",
       "1                                     NaN                [Daniel E. Acuna]   \n",
       "2    [chipy, ianbicking, pip, virtualenv]                     [Carl Meyer]   \n",
       "3  [Django, DjangoConEU, djangoconeu2021]                     [dhilipsiva]   \n",
       "4                                      []                  [Curtis Lassam]   \n",
       "\n",
       "  Duration  \n",
       "0     1993  \n",
       "1     2700  \n",
       "2     None  \n",
       "3     1837  \n",
       "4     None  "
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "path_to_json = './data/Videos/' \n",
    "\n",
    "json_pattern = os.path.join(path_to_json,'*.json')\n",
    "file_list = glob.glob(json_pattern)\n",
    " \n",
    "dfs = []\n",
    "for file in file_list:\n",
    "    with open(file) as f:\n",
    "        json_data = pd.json_normalize(json.loads(f.read()))\n",
    "    dfs.append(json_data)\n",
    "df = pd.concat(dfs, sort=False) # or sort=True depending on your needs\n",
    "df.index = pd.RangeIndex(len(df.index))\n",
    "\n",
    "url_list =[]\n",
    "for i in df.index:\n",
    "    url = df.videos[i][0]['url']\n",
    "    url_list.append(url)\n",
    "url_list\n",
    "df = df.assign(url = url_list)\n",
    "\n",
    "\n",
    "df['recorded'] = pd.to_datetime(df['recorded'])  \n",
    "\n",
    "\n",
    "df = df[['title','language','recorded','url','description','category','tags','speakers','duration']]\n",
    "df.rename(columns={\n",
    "        'title': 'Title', 'language': 'Lang',\n",
    "        'recorded': 'Record_date', 'url': 'url',\n",
    "        'description': 'Description', 'category': 'Category','tags':'Tags',\n",
    "        'description': 'Description', 'speakers': 'Speakers','duration':'Duration'}, inplace=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Handle Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    "Ø¯Ø± Ø§ÛŒÙ† Ù‚Ø³Ù…Øª Ø§Ø¨ØªØ¯Ø§ Ø¯Ø§Ø¯Ù‡ Ù‡Ø§ÛŒ NaN Ù…Ø±Ø¨ÙˆØ· Ø¨Ù‡ Ù‡Ø±Ú©Ø¯Ø§Ù… Ø§Ø² ÙˆÛŒØ²Ú¯ÛŒ Ù‡Ø§ Ú†Ø§Ù¾ Ù…ÛŒ Ú©Ù†ÛŒÙ… Ø³Ù¾Ø³ Ø¢Ù† Ù‡Ø§ Ø±Ø§ Ø¨Ø§ Ù…Ù‚Ø¯Ø§Ø± Ù…Ù†Ø§Ø³Ø¨ Ø¬Ø§ÛŒÚ¯Ø²ÛŒÙ† Ù…ÛŒ Ú©Ù†ÛŒÙ….\n",
    "Ø¨Ø±Ø§ÛŒ Ø¯Ùˆ ÙˆÛŒÚ˜Ú¯ÛŒ \n",
    "category\n",
    "Ùˆ\n",
    "Tags\n",
    "Ø§Ø² Ù…Ù‚Ø¯Ø§Ø± Ù‚Ø¨Ù„ÛŒ Ø§Ù† Ù‡Ø§ Ùˆ Ø¨Ø±Ø§ÛŒ ÙˆÛŒÚ˜Ú¯ÛŒ \n",
    "Duration\n",
    "Ø§Ø² Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ú©Ù„ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ø±Ø¯ÛŒÙ….\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title            0\n",
      "Lang             0\n",
      "Record_date      0\n",
      "url              0\n",
      "Description      0\n",
      "Category        35\n",
      "Tags             5\n",
      "Speakers         0\n",
      "Duration       176\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print ( df.isna().sum() )\n",
    "df['Duration'] = df['Duration'].fillna(df['Duration'].mean())\n",
    "df['Category'] = df['Category'].fillna(method='bfill')\n",
    "df['Tags'] = df['Tags'].fillna(method='bfill')\n",
    "df = df.fillna(method='bfill')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3: Title of videos published in 2016"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div dir=\"rtl\">\n",
    "Ø¯Ø± Ø§ÛŒÙ† Ù‚Ø³Ù…Øª Ø¹Ù†ÙˆØ§Ù† ÙˆÛŒØ¯ÛŒÙˆ Ù‡Ø§ÛŒ Ù…Ù†ØªØ´Ø± Ø´Ø¯Ù‡ Ø¯Ø± Ø³Ø§Ù„ Û²Û°Û±Û¶ Ø±Ø§ Ú†Ø§Ù¾ Ù…ÛŒ Ú©Ù†ÛŒÙ….\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Lang</th>\n",
       "      <th>Record_date</th>\n",
       "      <th>url</th>\n",
       "      <th>Description</th>\n",
       "      <th>Category</th>\n",
       "      <th>Tags</th>\n",
       "      <th>Speakers</th>\n",
       "      <th>Duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Python-based data science to understand knowle...</td>\n",
       "      <td>eng</td>\n",
       "      <td>2016-03-10</td>\n",
       "      <td>http://youtu.be/pVd2v7fgxwU</td>\n",
       "      <td>All kinds of businesses are using data science...</td>\n",
       "      <td>ChiPy</td>\n",
       "      <td>[chipy, ianbicking, pip, virtualenv]</td>\n",
       "      <td>[Daniel E. Acuna]</td>\n",
       "      <td>2700.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>ChiPy Python Mentorship</td>\n",
       "      <td>eng</td>\n",
       "      <td>2016-03-10</td>\n",
       "      <td>http://youtu.be/l9xwgde6J84</td>\n",
       "      <td>This April we will the start the fourth round ...</td>\n",
       "      <td>PyCon US 2015</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Tathagata]</td>\n",
       "      <td>420.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>The wonder and the horror of the mock module</td>\n",
       "      <td>eng</td>\n",
       "      <td>2016-03-10</td>\n",
       "      <td>http://youtu.be/PAt5P9mIALY</td>\n",
       "      <td>The \"mock\" module is a powerful (and fun!) too...</td>\n",
       "      <td>ChiPy</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Stephen Hoover]</td>\n",
       "      <td>300.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Title Lang Record_date  \\\n",
       "1   Python-based data science to understand knowle...  eng  2016-03-10   \n",
       "72                            ChiPy Python Mentorship  eng  2016-03-10   \n",
       "75       The wonder and the horror of the mock module  eng  2016-03-10   \n",
       "\n",
       "                            url  \\\n",
       "1   http://youtu.be/pVd2v7fgxwU   \n",
       "72  http://youtu.be/l9xwgde6J84   \n",
       "75  http://youtu.be/PAt5P9mIALY   \n",
       "\n",
       "                                          Description       Category  \\\n",
       "1   All kinds of businesses are using data science...          ChiPy   \n",
       "72  This April we will the start the fourth round ...  PyCon US 2015   \n",
       "75  The \"mock\" module is a powerful (and fun!) too...          ChiPy   \n",
       "\n",
       "                                    Tags           Speakers  Duration  \n",
       "1   [chipy, ianbicking, pip, virtualenv]  [Daniel E. Acuna]    2700.0  \n",
       "72                                    []        [Tathagata]     420.0  \n",
       "75                                    []   [Stephen Hoover]     300.0  "
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = df['Record_date'].dt.year == int(2016)\n",
    "include = df[mask]\n",
    "include"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 4: Mean, Min, Max, Median of Duration for each Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "median :  1479.485294117647\n",
      "mean :  1479.4852941176468\n",
      "max :  4328.0\n",
      "min :  4.0\n"
     ]
    }
   ],
   "source": [
    "print (\"median : \"  , df['Duration'].median() )\n",
    "print (\"mean : \"  ,df['Duration'].mean()     )\n",
    "print (\"max : \"  ,df['Duration'].max()     )\n",
    "print (\"min : \"  ,df['Duration'].min()     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 5: Create `label` Column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    "Ø¯Ø± Ø§ÛŒÙ† Ù‚Ø³Ù…Øª Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø§ÛŒØ¬Ø§Ø¯ Ø´Ø±Ø· Ù‡Ø§ÛŒ Ø¯Ø§Ø¯Ù‡ Ø´Ø¯Ù‡ Ø¯Ø± ØµÙˆØ±Øª Ø³ÙˆØ§Ù„ Ø³ØªÙˆÙ†\n",
    "label\n",
    "Ø±Ø§ Ø§ÛŒØ¬Ø§Ø¯ Ú©Ø±Ø¯Ù‡ Ùˆ Ù…Ø·Ø§Ø¨Ù‚ Ø¨Ø§ Ø´Ø±Ø· Ù‡Ø§ Ø¢Ù† Ø±Ø§ Ù¾Ø± Ú©Ø±Ø¯ÛŒÙ….\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Lang</th>\n",
       "      <th>Record_date</th>\n",
       "      <th>url</th>\n",
       "      <th>Description</th>\n",
       "      <th>Category</th>\n",
       "      <th>Tags</th>\n",
       "      <th>Speakers</th>\n",
       "      <th>Duration</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Load Testing a Django Application using LocustIO</td>\n",
       "      <td>eng</td>\n",
       "      <td>2021-06-04</td>\n",
       "      <td>https://www.youtube.com/watch?v=2rvsOQrbLuc</td>\n",
       "      <td>Fed up of using existing tools for determining...</td>\n",
       "      <td>ChiPy</td>\n",
       "      <td>[Django, DjangoConEU, djangoconeu2021]</td>\n",
       "      <td>[Pranjal Jain, Vibhash Chandra]</td>\n",
       "      <td>1993.000000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Python-based data science to understand knowle...</td>\n",
       "      <td>eng</td>\n",
       "      <td>2016-03-10</td>\n",
       "      <td>http://youtu.be/pVd2v7fgxwU</td>\n",
       "      <td>All kinds of businesses are using data science...</td>\n",
       "      <td>ChiPy</td>\n",
       "      <td>[chipy, ianbicking, pip, virtualenv]</td>\n",
       "      <td>[Daniel E. Acuna]</td>\n",
       "      <td>2700.000000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Reverse-engineering Ian Bicking's brain: insid...</td>\n",
       "      <td>eng</td>\n",
       "      <td>2011-02-10</td>\n",
       "      <td>https://archive.org/details/pyvideo_568___reve...</td>\n",
       "      <td>-  1 http://us.pycon.org/2011/schedule/session...</td>\n",
       "      <td>ChiPy</td>\n",
       "      <td>[chipy, ianbicking, pip, virtualenv]</td>\n",
       "      <td>[Carl Meyer]</td>\n",
       "      <td>1479.485294</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Build, deploy and scale Django, GraphQL and SPA</td>\n",
       "      <td>eng</td>\n",
       "      <td>2021-06-04</td>\n",
       "      <td>https://www.youtube.com/watch?v=x9I6WaaLC3U</td>\n",
       "      <td>After building, deploying and scaling a dozen ...</td>\n",
       "      <td>PyCon US 2015</td>\n",
       "      <td>[Django, DjangoConEU, djangoconeu2021]</td>\n",
       "      <td>[dhilipsiva]</td>\n",
       "      <td>1837.000000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hash Functions and You: Partners in Freedom</td>\n",
       "      <td>eng</td>\n",
       "      <td>2015-04-12</td>\n",
       "      <td>https://www.youtube.com/watch?v=IGwNQfjLTp0</td>\n",
       "      <td>Our trusty friend, the hash function, is as cr...</td>\n",
       "      <td>PyCon US 2015</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Curtis Lassam]</td>\n",
       "      <td>1479.485294</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title Lang Record_date  \\\n",
       "0   Load Testing a Django Application using LocustIO  eng  2021-06-04   \n",
       "1  Python-based data science to understand knowle...  eng  2016-03-10   \n",
       "2  Reverse-engineering Ian Bicking's brain: insid...  eng  2011-02-10   \n",
       "3    Build, deploy and scale Django, GraphQL and SPA  eng  2021-06-04   \n",
       "4        Hash Functions and You: Partners in Freedom  eng  2015-04-12   \n",
       "\n",
       "                                                 url  \\\n",
       "0        https://www.youtube.com/watch?v=2rvsOQrbLuc   \n",
       "1                        http://youtu.be/pVd2v7fgxwU   \n",
       "2  https://archive.org/details/pyvideo_568___reve...   \n",
       "3        https://www.youtube.com/watch?v=x9I6WaaLC3U   \n",
       "4        https://www.youtube.com/watch?v=IGwNQfjLTp0   \n",
       "\n",
       "                                         Description       Category  \\\n",
       "0  Fed up of using existing tools for determining...          ChiPy   \n",
       "1  All kinds of businesses are using data science...          ChiPy   \n",
       "2  -  1 http://us.pycon.org/2011/schedule/session...          ChiPy   \n",
       "3  After building, deploying and scaling a dozen ...  PyCon US 2015   \n",
       "4  Our trusty friend, the hash function, is as cr...  PyCon US 2015   \n",
       "\n",
       "                                     Tags                         Speakers  \\\n",
       "0  [Django, DjangoConEU, djangoconeu2021]  [Pranjal Jain, Vibhash Chandra]   \n",
       "1    [chipy, ianbicking, pip, virtualenv]                [Daniel E. Acuna]   \n",
       "2    [chipy, ianbicking, pip, virtualenv]                     [Carl Meyer]   \n",
       "3  [Django, DjangoConEU, djangoconeu2021]                     [dhilipsiva]   \n",
       "4                                      []                  [Curtis Lassam]   \n",
       "\n",
       "      Duration  label  \n",
       "0  1993.000000      2  \n",
       "1  2700.000000      3  \n",
       "2  1479.485294      2  \n",
       "3  1837.000000      2  \n",
       "4  1479.485294      2  "
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conditions = [\n",
    "    (df['Duration'] <= 1000),\n",
    "    (df['Duration'] > 1000) & (df['Duration'] <= 2000),\n",
    "    (df['Duration'] > 2000)\n",
    "    ]\n",
    "values = [1, 2, 3]\n",
    "df['label'] = np.select(conditions, values)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 6: First and Last video of each label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    "Ø¯Ø± Ø§ÛŒÙ† Ù‚Ø³Ù…Øª Ø¹Ù†ÙˆØ§Ù† ÙˆÛŒØ¯ÛŒÙˆ Ù‡Ø§ÛŒ Ù…Ù†ØªØ´Ø± Ø´Ø¯Ù‡ Ø¯Ø± Ø³Ø§Ù„ Û²Û°Û±Û¶ Ø±Ø§ Ú†Ø§Ù¾ Ù…ÛŒ Ú©Ù†ÛŒÙ….\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Lang</th>\n",
       "      <th>Record_date</th>\n",
       "      <th>url</th>\n",
       "      <th>Description</th>\n",
       "      <th>Category</th>\n",
       "      <th>Tags</th>\n",
       "      <th>Speakers</th>\n",
       "      <th>Duration</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Record_date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2014-07-09</th>\n",
       "      <td>Python-based data science to understand knowle...</td>\n",
       "      <td>eng</td>\n",
       "      <td>2016-03-10</td>\n",
       "      <td>http://youtu.be/pVd2v7fgxwU</td>\n",
       "      <td>All kinds of businesses are using data science...</td>\n",
       "      <td>ChiPy</td>\n",
       "      <td>[chipy, ianbicking, pip, virtualenv]</td>\n",
       "      <td>[Daniel E. Acuna]</td>\n",
       "      <td>2700.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-11</th>\n",
       "      <td>All about The Django Software Foundation DSF</td>\n",
       "      <td>eng</td>\n",
       "      <td>2021-06-04</td>\n",
       "      <td>https://www.youtube.com/watch?v=Z_e-QoeZwEM</td>\n",
       "      <td>The Django Software Foundation (DSF) is the in...</td>\n",
       "      <td>ChiPy</td>\n",
       "      <td>[Django, DjangoConEU, djangoconeu2021]</td>\n",
       "      <td>[Anna Makarudze]</td>\n",
       "      <td>2183.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-03-12</th>\n",
       "      <td>The request response cycle a Djangonautic journey</td>\n",
       "      <td>eng</td>\n",
       "      <td>2021-06-04</td>\n",
       "      <td>https://www.youtube.com/watch?v=P5gQmlrwLjc</td>\n",
       "      <td>How exactly do web-servers communicate with Dj...</td>\n",
       "      <td>PyCon US 2015</td>\n",
       "      <td>[Django, DjangoConEU, djangoconeu2021]</td>\n",
       "      <td>[Timothy McCurrach]</td>\n",
       "      <td>2354.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-10</th>\n",
       "      <td>A SQL for Django</td>\n",
       "      <td>eng</td>\n",
       "      <td>2021-06-02</td>\n",
       "      <td>https://www.youtube.com/watch?v=kIwGM-e7EhM</td>\n",
       "      <td>This talk will show you how to combine SQL and...</td>\n",
       "      <td>PyCon US 2015</td>\n",
       "      <td>[Django, DjangoConEU, djangoconeu2021]</td>\n",
       "      <td>[Stefan Baerisch]</td>\n",
       "      <td>2126.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-20</th>\n",
       "      <td>Create a full stack, reactive website in Djang...</td>\n",
       "      <td>eng</td>\n",
       "      <td>2021-06-03</td>\n",
       "      <td>https://www.youtube.com/watch?v=wMiZIK8p6DQ</td>\n",
       "      <td>Django is a great web framework for \"perfectio...</td>\n",
       "      <td>PyCon US 2015</td>\n",
       "      <td>[Django, DjangoConEU, djangoconeu2021]</td>\n",
       "      <td>[Adam Hill]</td>\n",
       "      <td>2542.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         Title Lang  \\\n",
       "Record_date                                                           \n",
       "2014-07-09   Python-based data science to understand knowle...  eng   \n",
       "2014-12-11        All about The Django Software Foundation DSF  eng   \n",
       "2015-03-12   The request response cycle a Djangonautic journey  eng   \n",
       "2016-03-10                                    A SQL for Django  eng   \n",
       "2019-11-20   Create a full stack, reactive website in Djang...  eng   \n",
       "\n",
       "            Record_date                                          url  \\\n",
       "Record_date                                                            \n",
       "2014-07-09   2016-03-10                  http://youtu.be/pVd2v7fgxwU   \n",
       "2014-12-11   2021-06-04  https://www.youtube.com/watch?v=Z_e-QoeZwEM   \n",
       "2015-03-12   2021-06-04  https://www.youtube.com/watch?v=P5gQmlrwLjc   \n",
       "2016-03-10   2021-06-02  https://www.youtube.com/watch?v=kIwGM-e7EhM   \n",
       "2019-11-20   2021-06-03  https://www.youtube.com/watch?v=wMiZIK8p6DQ   \n",
       "\n",
       "                                                   Description       Category  \\\n",
       "Record_date                                                                     \n",
       "2014-07-09   All kinds of businesses are using data science...          ChiPy   \n",
       "2014-12-11   The Django Software Foundation (DSF) is the in...          ChiPy   \n",
       "2015-03-12   How exactly do web-servers communicate with Dj...  PyCon US 2015   \n",
       "2016-03-10   This talk will show you how to combine SQL and...  PyCon US 2015   \n",
       "2019-11-20   Django is a great web framework for \"perfectio...  PyCon US 2015   \n",
       "\n",
       "                                               Tags             Speakers  \\\n",
       "Record_date                                                                \n",
       "2014-07-09     [chipy, ianbicking, pip, virtualenv]    [Daniel E. Acuna]   \n",
       "2014-12-11   [Django, DjangoConEU, djangoconeu2021]     [Anna Makarudze]   \n",
       "2015-03-12   [Django, DjangoConEU, djangoconeu2021]  [Timothy McCurrach]   \n",
       "2016-03-10   [Django, DjangoConEU, djangoconeu2021]    [Stefan Baerisch]   \n",
       "2019-11-20   [Django, DjangoConEU, djangoconeu2021]          [Adam Hill]   \n",
       "\n",
       "             Duration  label  \n",
       "Record_date                   \n",
       "2014-07-09     2700.0      3  \n",
       "2014-12-11     2183.0      3  \n",
       "2015-03-12     2354.0      3  \n",
       "2016-03-10     2126.0      3  \n",
       "2019-11-20     2542.0      3  "
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = df.copy()\n",
    "df_label1 = df2.loc[df2['label'] == 1]\n",
    "df_label2 = df2.loc[df2['label'] == 2]\n",
    "df_label3 = df2.loc[df2['label'] == 3]\n",
    "\n",
    "\n",
    "df_label1 = df_label1.set_index(pd.DatetimeIndex(df_label1['Record_date']).sort_values())\n",
    "df_label2 = df_label2.set_index(pd.DatetimeIndex(df_label2['Record_date']).sort_values())\n",
    "df_label3 = df_label3.set_index(pd.DatetimeIndex(df_label3['Record_date']).sort_values())\n",
    "\n",
    "#df2.reindex()\n",
    "df_label3.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Bonus) part 7: WordCloud of Discription"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    " Ø¯Ø± Ø§ÛŒÙ† Ù‚Ø³Ù…Øª Ø§Ø¨ØªØ¯Ø§ Ù…ÛŒ Ø®ÙˆØ§Ù‡ÛŒÙ… \n",
    " stop word\n",
    " Ù‡Ø§ Ø±Ø§ Ø­Ø°Ù Ú©Ù†ÛŒÙ… Ø¨Ù‡ Ù‡Ù…ÛŒÙ† Ø¹Ù„Øª Ø§ÙˆÙ„ Ú©ØªØ§Ø¨Ø®Ø§Ù†Ù‡ \n",
    " nltk\n",
    " Ø±Ø§ Ø®ÙˆØ§Ù†Ø¯Ù‡ Ùˆ Ù¾Ú©Ø¬ \n",
    " stopwords\n",
    " Ø±Ø§ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù…ÛŒ Ú©Ù†ÛŒÙ…:\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/carltonj.lloyd/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Import stopwords with nltk.\n",
    "import nltk\n",
    "import ssl\n",
    "\n",
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "else:\n",
    "    ssl._create_default_https_context = _create_unverified_https_context\n",
    "\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    "Ø¯Ø± Ø§Ø¯Ø§Ù…Ù‡ Ø§Ø¨ØªØ¯Ø§ Ø®Ø· ÙØ§ØµÙ„Ù‡ Ø±Ø§ Ø­Ø°Ù Ú©Ø±Ø¯Ù‡ØŒ Ø³Ù¾Ø³ Ú©Ù„Ù…Ø§Øª Ø³ØªÙˆÙ† \n",
    "description\n",
    "Ø±Ø§ Ø¬Ø¯Ø§ Ú©Ø±Ø¯Ù‡ Ùˆ Ø¯Ø± Ø§Ø¨Ù†ØªÙ‡Ø§ Ù†ÛŒØ²  Ø§Ø¨Ø± Ú©Ù„Ù…Ø§Øª Ø±Ø§ Ø¨Ø±Ø§ÛŒ ÛµÛ° Ú©Ù„Ù…Ù‡ Ù¾Ø± ØªÚ©Ø±Ø§Ø± Ø¨Ø¯Ø³Øª Ù…ÛŒ Ø§ÙˆØ±ÛŒÙ….\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Common Words in Description Column are :\n",
      "python          125\n",
      "django           88\n",
      "talk             84\n",
      "this             80\n",
      "use              73\n",
      "web              54\n",
      "using            53\n",
      "i                45\n",
      "data             44\n",
      "the              41\n",
      "code             41\n",
      "in               40\n",
      "learn            37\n",
      "like             35\n",
      "build            31\n",
      "we               29\n",
      "make             29\n",
      "we'll            28\n",
      "get              27\n",
      "new              26\n",
      "application      26\n",
      "also             25\n",
      "tutorial         24\n",
      "want             24\n",
      "real             24\n",
      "software         23\n",
      "show             23\n",
      "framework        22\n",
      "know             21\n",
      "cover            21\n",
      "applications     20\n",
      "programming      20\n",
      "way              20\n",
      "rest             20\n",
      "performance      19\n",
      "learning         19\n",
      "i'll             19\n",
      "many             19\n",
      "used             19\n",
      "language         19\n",
      "best             18\n",
      "it               18\n",
      "testing          17\n",
      "open             17\n",
      "world            17\n",
      "what             17\n",
      "scientific       17\n",
      "introduction     17\n",
      "tools            17\n",
      "and              16\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "stop = stopwords.words('english')\n",
    "\n",
    "\n",
    "df3['Description']=df3['Description'].str.replace('-',' ')\n",
    "df3['Description'] = df3['Description'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
    "print(\"Most Common Words in Description Column are :\")\n",
    "print ( pd.Series(' '.join(df3['Description']).lower().split()).value_counts()[:50] )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0adcc2737ebf6a4a119f135174df96668767fca1ef1112612db5ecadf2b6d608"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
